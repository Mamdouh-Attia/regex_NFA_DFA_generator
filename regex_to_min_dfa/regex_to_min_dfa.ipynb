{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkHVQz0bDkZZ"
      },
      "source": [
        "#    Compilers and Languages\n",
        "## Programming assignment : Part 1 : input regex -> NFA\n",
        "\n",
        "Table of Contents:\n",
        "1. [The Shunting Yard Algorithm](#1.-Introduction---Shunting-Yard-Algorithm)\n",
        "2. [Postfix to NFA](#2.-Postfix-to-NFA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZOw_AwxDkZb"
      },
      "source": [
        "# The shunting yard algorithm (infix to postfix)\n",
        "\n",
        "### Introduction\n",
        "The shunting yard algorithm is a method for parsing mathematical expressions specified in infix notation. It can be used to produce output in Reverse Polish Notation (RPN) or as an abstract syntax tree (AST). The algorithm was invented by Edsger Dijkstra and named the \"shunting yard\" algorithm because its operation resembles that of a railroad shunting yard.\n",
        "\n",
        "We will use the shunting yard algorithm to convert the regular expression to postfix notation, which will be used to create the NFA.\n",
        "\n",
        "### Goal\n",
        "converting something like `(A+B) * (C | D)` to `A+B . * CD |.`\n",
        "\n",
        "### Features\n",
        ". No recursion => Iterative approach.\n",
        ". No trees are needed.\n",
        ". No Ambiguities.\n",
        ". Handles precedence of operators.\n",
        "\n",
        "### Data Structures\n",
        "1. infix (input regex) : The regular expression in infix notation (string)\n",
        "   . Note : infix means the operator is between the operands. eg: `A+B` (The normal way we write expressions)\n",
        "2. postfix : The regular expression in postfix notation (string)\n",
        "    . Note : postfix means the operator is after the operands. eg: `AB+` (The way we write expressions in the shunting yard algorithm)\n",
        "3. stack : The stack used in the algorithm (list)\n",
        "\n",
        "### Algorithm\n",
        "0. preprocess the infix to add a `.` between the operands where needed. (eg: `A(B|C)` => `A.(B|C)`). also substitute ranges like `a-z` with the union of all the characters in the range.\n",
        "1. Create an empty stack for operators. Create an empty list for the output.\n",
        "2. For each character in the infix :\n",
        "    - If char is `(` or `[` => push to stack\n",
        "    - If char is `)` or `]` => pop from stack until nearest matching `(` or `[` , append to output\n",
        "    - If char is an operator => pop from stack until the top of the stack has a lower precedence than the current operator, then push the current operator to the stack\n",
        "    - If char is an operand/normal character => append to output\n",
        "3. Pop all the remaining operators from the stack and append to the output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RbrSVpK7DkZc"
      },
      "outputs": [],
      "source": [
        "# Important declarations\n",
        "# -----------------------\n",
        "# Dictionary containing the precedence of the operators\n",
        "regex_operators_precedence = {\n",
        "    '*' : 5,\n",
        "    '+' : 4,\n",
        "    '?' : 3,\n",
        "    '.' : 2,\n",
        "    '|' : 1,\n",
        "    '(' : 0,\n",
        "    ')' : 0\n",
        "}\n",
        "\n",
        "alphanumeric = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
        "alphabetic = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXmQwNbHDkZd"
      },
      "source": [
        "## Preprocessing ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NXE5FqFYDkZd"
      },
      "outputs": [],
      "source": [
        "# Utility functions\n",
        "# -----------------\n",
        "def preprocess_regex(regex):\n",
        "    \"\"\"\n",
        "    Preprocess the regex to do the following:\n",
        "        1-[ranges] add OR's | between in square brackets characters\n",
        "        2-[ranges] replace dash - with the corresponding sequence of characters with OR's between them\n",
        "        3-add the missing '.' operators\n",
        "    \"\"\"\n",
        "    #step 1 : add OR's | between in square brackets characters without -\n",
        "    square_brackets_open = False\n",
        "    for i in range(len(regex)):\n",
        "        if regex[i] == '[':\n",
        "            square_brackets_open = True\n",
        "        elif regex[i] == ']':\n",
        "            square_brackets_open = False\n",
        "        elif square_brackets_open and regex[i] != '-' and regex[i] in alphanumeric and i+1 < len(regex) and regex[i+1] in alphanumeric:\n",
        "            regex = regex[:i+1] + '|' + regex[i+1:]\n",
        "    print(f\"After step 1 : {regex}\")\n",
        "    #step 2 : replace dash - with the corresponding sequence of characters with OR's between them\n",
        "    i = 0\n",
        "    while i < len(regex):\n",
        "        c = regex[i]\n",
        "        print(f\"i = {i}, c = {c}\")\n",
        "        if c == '-':\n",
        "            #pop the last element from the stack\n",
        "            first = regex[i-1] if regex[i-1] in alphanumeric else None\n",
        "            if not first:\n",
        "                raise ValueError('Range error: element after - is not alphanumeric')\n",
        "            #access Char + 1\n",
        "            last = regex[i + 1] if i+1 < len(regex) and regex[i+1] in alphanumeric else None\n",
        "            if not last:\n",
        "                raise ValueError('Range error: element after - is not alphanumeric')\n",
        "            #throw the - operator from the regex\n",
        "            operating_list = []\n",
        "            for char in alphanumeric:\n",
        "                if alphanumeric.index(char) > alphanumeric.index(first) and alphanumeric.index(char) < alphanumeric.index(last):\n",
        "                    #append | between the characters\n",
        "                    # if char != last:\n",
        "                    operating_list.append('|')\n",
        "                    operating_list.append(char)\n",
        "            operating_list.append('|')\n",
        "            #replace - in regex with the operating list\n",
        "            #using i to get the index of the first character in the range\n",
        "            regex = regex[:i] + ''.join(operating_list) + regex[i+1:]\n",
        "            i += len(operating_list)\n",
        "        i += 1\n",
        "\n",
        "    print(f\"After step 2 : {regex}\")\n",
        "    #step 3 : add the missing '.' operators\n",
        "    check1_list = ['*', '+', '?', ')', ']']\n",
        "    new_regex = ''\n",
        "    for i,c in enumerate(regex):\n",
        "        if i > 0 and c in check1_list and i+1 < len(regex) and regex[i+1] not in check1_list:\n",
        "            new_regex += c + '.'\n",
        "        elif c in alphanumeric and i+1 < len(regex) and ((regex[i+1] in alphanumeric) or regex[i+1] in ['(', '[']):\n",
        "            new_regex += c + '.'\n",
        "        else:\n",
        "            new_regex += c\n",
        "    print(f\"After step 3 : {new_regex} Preprocessed!\")\n",
        "    return new_regex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GzKeVXnaDkZe"
      },
      "outputs": [],
      "source": [
        "def infix_to_postfix(regex):\n",
        "    \"\"\"\n",
        "    Convert an infix regular expression to a postfix regular expression.\n",
        "\n",
        "    Parameters:\n",
        "    regex (str): The infix regular expression to convert to postfix.\n",
        "\n",
        "    Returns:\n",
        "    str: The postfix regular expression.\n",
        "    \"\"\"\n",
        "    regex = preprocess_regex(regex)\n",
        "    # Create a stack to hold the operators\n",
        "    stack = []\n",
        "    # Create a list to hold the postfix regular expression\n",
        "    postfix = []\n",
        "    # Iterate over the characters in the infix regular expression\n",
        "    for index,char in enumerate(regex):\n",
        "        #1. '(' or '[': Push it onto the stack\n",
        "        if char == '(' or char == '[':\n",
        "            stack.append(char)\n",
        "        #2. ')' or ']': Pop operators from the stack and append them to the postfix list until '(' or '[' is found\n",
        "        elif char == ')' :\n",
        "            while stack[-1] != '(':\n",
        "                postfix.append(stack.pop())\n",
        "            #error handling : check empty stack\n",
        "            if not stack:\n",
        "                raise ValueError('Parentheses mismatch : found \")\" in the stack without \"(\"')\n",
        "            stack.pop()\n",
        "        elif char == ']':\n",
        "            while stack[-1] != '[':\n",
        "                postfix.append(stack.pop())\n",
        "            #error handling : check empty stack\n",
        "            if not stack:\n",
        "                raise ValueError('Parentheses mismatch : found \"]\" in the stack without \"[\"')\n",
        "            stack.pop()\n",
        "        #3. Operator: Pop operators from the stack and append them to the postfix list until an operator with lower precedence is found\n",
        "        elif char in regex_operators_precedence:\n",
        "            #checks:\n",
        "            # 1. if the stack is not empty\n",
        "            # 2. if the stack[-1] is an operator => meaning the last element in the stack is an operator\n",
        "            # 3. if the precedence of the operator in the stack is greater than or equal to the precedence of the current operator\n",
        "            while stack and stack[-1] in regex_operators_precedence and regex_operators_precedence[stack[-1]] >= regex_operators_precedence[char]:\n",
        "                postfix.append(stack.pop())\n",
        "            stack.append(char)\n",
        "        #else: Append the character to the postfix list\n",
        "        else:\n",
        "            # A normal character => append it to the postfix list\n",
        "            postfix.append(char)\n",
        "        # empty the stack\n",
        "    while stack:\n",
        "        #error handling : check '(' in the stack\n",
        "        if stack[-1] == '(':\n",
        "            raise ValueError('Parentheses mismatch : found \"(\" in the stack without \")\"')\n",
        "        postfix.append(stack.pop())\n",
        "    return ''.join(postfix)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or53n4iSDkZe",
        "outputId": "e9d211e0-e46a-4ca4-9db0-c563d4acca60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After step 1 : [a-z|A-Z]+\n",
            "i = 0, c = [\n",
            "i = 1, c = a\n",
            "i = 2, c = -\n",
            "i = 52, c = |\n",
            "i = 53, c = A\n",
            "i = 54, c = -\n",
            "i = 104, c = ]\n",
            "i = 105, c = +\n",
            "After step 2 : [a|b|c|d|e|f|g|h|i|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z|A|B|C|D|E|F|G|H|I|J|K|L|M|N|O|P|Q|R|S|T|U|V|W|X|Y|Z]+\n",
            "After step 3 : [a|b|c|d|e|f|g|h|i|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z|A|B|C|D|E|F|G|H|I|J|K|L|M|N|O|P|Q|R|S|T|U|V|W|X|Y|Z]+ Preprocessed!\n",
            "ab|c|d|e|f|g|h|i|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z|A|B|C|D|E|F|G|H|I|J|K|L|M|N|O|P|Q|R|S|T|U|V|W|X|Y|Z|+\n",
            "After step 1 : [f-p|0-9]+(a*bcd?|cde*)\n",
            "i = 0, c = [\n",
            "i = 1, c = f\n",
            "i = 2, c = -\n",
            "i = 22, c = |\n",
            "i = 23, c = 0\n",
            "i = 24, c = -\n",
            "i = 42, c = ]\n",
            "i = 43, c = +\n",
            "i = 44, c = (\n",
            "i = 45, c = a\n",
            "i = 46, c = *\n",
            "i = 47, c = b\n",
            "i = 48, c = c\n",
            "i = 49, c = d\n",
            "i = 50, c = ?\n",
            "i = 51, c = |\n",
            "i = 52, c = c\n",
            "i = 53, c = d\n",
            "i = 54, c = e\n",
            "i = 55, c = *\n",
            "i = 56, c = )\n",
            "After step 2 : [f|g|h|i|j|k|l|m|n|o|p|0|1|2|3|4|5|6|7|8|9]+(a*bcd?|cde*)\n",
            "After step 3 : [f|g|h|i|j|k|l|m|n|o|p|0|1|2|3|4|5|6|7|8|9]+.(a*.b.c.d?.|c.d.e*) Preprocessed!\n",
            "fg|h|i|j|k|l|m|n|o|p|0|1|2|3|4|5|6|7|8|9|+a*b.c.d?..cd.e*.|.\n",
            "After step 1 : [a-c]?.(c|d)\n",
            "i = 0, c = [\n",
            "i = 1, c = a\n",
            "i = 2, c = -\n",
            "i = 6, c = ]\n",
            "i = 7, c = ?\n",
            "i = 8, c = .\n",
            "i = 9, c = (\n",
            "i = 10, c = c\n",
            "i = 11, c = |\n",
            "i = 12, c = d\n",
            "i = 13, c = )\n",
            "After step 2 : [a|b|c]?.(c|d)\n",
            "After step 3 : [a|b|c]?..(c|d) Preprocessed!\n",
            "ab|c|?.cd|.\n",
            "All test cases passed!\n"
          ]
        }
      ],
      "source": [
        "# test cases\n",
        "# ----------\n",
        "def test (id,regex, expected_postfix):\n",
        "    output =infix_to_postfix(regex)\n",
        "    print(f\"Test case #{id} : {regex} received : {output} expected : {expected_postfix} => Passed\")\n",
        "    assert output == expected_postfix\n",
        "\n",
        "# test(1,'a+b*c', 'a+b*.c.')\n",
        "# test(2,'[a-z]+', 'a|b|c|d|e|f|g|h|i|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z+')\n",
        "print(infix_to_postfix('[a-zA-Z]+'))\n",
        "print(infix_to_postfix('[f-p0-9]+(a*bcd?|cde*)'))\n",
        "\n",
        "print(infix_to_postfix('[a-c]?.(c|d)'))\n",
        "\n",
        "print('All test cases passed!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us-bM_2iDkZe"
      },
      "source": [
        "# Postfix to NFA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBkheiD4DkZf"
      },
      "source": [
        "## OOP Classes\n",
        "\n",
        "### edge\n",
        "1. label : The label of the edge\n",
        "2. destination : The destination state of the edge\n",
        "### state\n",
        "1. label : The label of the state\n",
        "2. out_edges : The outgoing edges from the state\n",
        "\n",
        "### NFA\n",
        "1. start : The start state of the NFA\n",
        "2. accept : The accept state of the NFA\n",
        "3. inner_states : The inner states of the NFA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "O4FkYbiwDkZf"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../pkg')  # Add the parent directory of pkg to the Python path\n",
        "from classes import NFA, NFA_state, edge, SuperState, DFA, LowerTriangularMatrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENMdaYJDDkZg"
      },
      "source": [
        "## Algorithm\n",
        "### Based on Thompson's construction algorithm\n",
        "1. Create a stack for NFA fragments\n",
        "2. For each character in the postfix :\n",
        "   1. If char is an operand/normal character => create a new NFA fragment with the character as the label and push to stack\n",
        "   2. If char is a `.` => pop 2 fragments from the stack, connect the accept state of the first fragment to the start state of the second fragment, and push the new fragment to the stack\n",
        "   3. If char is a `|` => pop 2 fragments from the stack, create a new start state and connect it to the start states of the 2 fragments, create a new accept state and connect the accept states of the 2 fragments to the new accept state, and push the new fragment to the stack\n",
        "   4. If char is a `*` => pop 1 fragment from the stack, create a new start state and connect it to the start state of the fragment, create a new accept state and connect the accept states of the fragment to the new accept state, and connect the accept state of the fragment to the start state of the fragment, and push the new fragment to the stack\n",
        "   5. If char is a `+` => pop 1 fragment from the stack, create a new start state and connect it to the start state of the fragment, create a new accept state and connect the accept states of the fragment to the new accept state, and connect the accept state of the fragment to the start state of the fragment, and push the new fragment to the stack\n",
        "   6. If char is a `?` => pop 1 fragment from the stack, create a new start state and connect it to the start state of the fragment, create a new accept state and connect the accept states of the fragment to the new accept state, and push the new fragment to the stack\n",
        "3. The final NFA is the fragment left in the stack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0cDurqZcDkZg"
      },
      "outputs": [],
      "source": [
        "# Important functions [Thomas Construction Algorithm]\n",
        "# -------------------\n",
        "'''\n",
        "1. Create a new NFA for a given character\n",
        "2. Concatenate two NFAs\n",
        "3. Union of two NFAs\n",
        "4. Zero or more of an NFA\n",
        "5. One or more of an NFA\n",
        "6. Zero or one of an NFA\n",
        "'''\n",
        "\n",
        "def create_nfa(char: str, id: int ,fragment_stack):\n",
        "    '''\n",
        "    Create a new NFA for a given character\n",
        "\n",
        "    Parameters:\n",
        "    char (str): The character to create the NFA for.\n",
        "    id (int): The id of the new NFA, used to label the states.\n",
        "    fragment_stack (list): The stack of NFA fragments.\n",
        "\n",
        "    Returns:\n",
        "    NFA: The NFA for the given character.\n",
        "    '''\n",
        "    #create two states for the new NFA\n",
        "    initial = NFA_state()\n",
        "    accept = NFA_state()\n",
        "    #Dummy label in format of S0 , S1, S2, ...\n",
        "    initial.label = f\"S{id}\"\n",
        "    accept.label = f\"S{id+1}\"\n",
        "    #create an edge from initial to accept with the given character\n",
        "    edg = edge()\n",
        "    edg.label = char\n",
        "    edg.destination = accept\n",
        "    initial.out_edges.append(edg)\n",
        "    #push the new NFA to the stack\n",
        "    created_nfa = NFA(initial, accept, [initial, accept])\n",
        "    fragment_stack.append(created_nfa)\n",
        "    id += 2\n",
        "    return created_nfa\n",
        "\n",
        "def concatenate_nfas(fragment_stack):\n",
        "    '''\n",
        "    Concatenate two NFAs, popping them from the stack and pushing the result back.\n",
        "\n",
        "    Parameters:\n",
        "    fragment_stack (list): The stack of NFA fragments.\n",
        "\n",
        "    Returns:\n",
        "    NFA: The NFA resulting from concatenating the top two NFAs on the stack.\n",
        "    '''\n",
        "    #pop the top two NFAs from the stack\n",
        "    nfa2 = fragment_stack.pop()\n",
        "    nfa1 = fragment_stack.pop()\n",
        "    #create an edge from the accept state of the first NFA to the start state of the second NFA\n",
        "    edg = edge()\n",
        "    edg.label = \"ε\"\n",
        "    edg.destination = nfa2.start\n",
        "    nfa1.accept.out_edges.append(edg)\n",
        "    #push the concatenated NFA back to the stack\n",
        "    concatenated_nfa = NFA(nfa1.start, nfa2.accept, nfa1.inner_states + nfa2.inner_states)\n",
        "    fragment_stack.append(concatenated_nfa)\n",
        "    return concatenated_nfa\n",
        "\n",
        "def union_nfas(fragment_stack , id : int):\n",
        "    '''\n",
        "    Union of two NFAs, popping them from the stack and pushing the result back.\n",
        "\n",
        "    Parameters:\n",
        "    fragment_stack (list): The stack of NFA fragments.\n",
        "    id (int): The id of the new NFA, used to label the states.\n",
        "\n",
        "    Returns:\n",
        "    NFA: The NFA resulting from union of the top two NFAs on the stack.\n",
        "    '''\n",
        "    #pop the top two NFAs from the stack\n",
        "    nfa2 = fragment_stack.pop()\n",
        "    nfa1 = fragment_stack.pop()\n",
        "    #create two new states for the new NFA\n",
        "    '''\n",
        "    [S0] --ε--> [nfa1.start] --ε--> [S1]\n",
        "        |ε                          |\n",
        "        ----> [nfa2.start] --  ε  --|\n",
        "    '''\n",
        "    initial = NFA_state()\n",
        "    accept = NFA_state()\n",
        "    initial.label = f\"S{id}\"\n",
        "    accept.label = f\"S{id+1}\"\n",
        "    #create two edges from the new initial state to the start states of the two NFAs\n",
        "    edg1 = edge()\n",
        "    edg1.label = \"ε\"\n",
        "    edg1.destination = nfa1.start\n",
        "    initial.out_edges.append(edg1)\n",
        "    edg2 = edge()\n",
        "    edg2.label = \"ε\"\n",
        "    edg2.destination = nfa2.start\n",
        "    initial.out_edges.append(edg2)\n",
        "    #create two edges from the accept states of the two NFAs to the new accept state\n",
        "    edg3 = edge()\n",
        "    edg3.label = \"ε\"\n",
        "    edg3.destination = accept\n",
        "    nfa1.accept.out_edges.append(edg3)\n",
        "    edg4 = edge()\n",
        "    edg4.label = \"ε\"\n",
        "    edg4.destination = accept\n",
        "    nfa2.accept.out_edges.append(edg4)\n",
        "    #push the union NFA back to the stack\n",
        "    union_nfa = NFA(initial, accept, [initial, accept] + nfa1.inner_states + nfa2.inner_states )\n",
        "    fragment_stack.append(union_nfa)\n",
        "    id += 2\n",
        "    return union_nfa\n",
        "\n",
        "def zero_or_more_nfa(fragment_stack, id: int):\n",
        "    '''\n",
        "    Zero or more of an NFA, popping it from the stack and pushing the result back.\n",
        "\n",
        "    Parameters:\n",
        "    fragment_stack (list): The stack of NFA fragments.\n",
        "    id (int): The id of the new NFA, used to label the states.\n",
        "\n",
        "    Returns:\n",
        "    NFA: The NFA resulting from zero or more of the top NFA on the stack.\n",
        "    '''\n",
        "    #pop the top NFA from the stack\n",
        "    nfa = fragment_stack.pop()\n",
        "    #create two new states for the new NFA\n",
        "    initial = NFA_state()\n",
        "    accept = NFA_state()\n",
        "    initial.label = f\"S{id}\"\n",
        "    accept.label = f\"S{id+1}\"\n",
        "    #create two edges from the new initial state to the start state of the NFA and to the new accept state\n",
        "    edg1 = edge()\n",
        "    edg1.label = \"ε\"\n",
        "    edg1.destination = nfa.start\n",
        "    initial.out_edges.append(edg1)\n",
        "    edg2 = edge()\n",
        "    edg2.label = \"ε\"\n",
        "    edg2.destination = accept\n",
        "    initial.out_edges.append(edg2)\n",
        "    #create two edges from the accept state of the NFA to the new accept state and to the initial state of the new NFA\n",
        "    edg3 = edge()\n",
        "    edg3.label = \"ε\"\n",
        "    edg3.destination = initial\n",
        "    nfa.accept.out_edges.append(edg3)\n",
        "    edg4 = edge()\n",
        "    edg4.label = \"ε\"\n",
        "    edg4.destination = accept\n",
        "    nfa.accept.out_edges.append(edg4)\n",
        "    #push the zero or more NFA back to the stack\n",
        "    zero_or_more_nfa = NFA(initial, accept, [initial, accept] + nfa.inner_states)\n",
        "    fragment_stack.append(zero_or_more_nfa)\n",
        "    id += 2\n",
        "    return zero_or_more_nfa\n",
        "\n",
        "def one_or_more_nfa(fragment_stack, id: int):\n",
        "    '''\n",
        "    One or more of an NFA, popping it from the stack and pushing the result back.\n",
        "\n",
        "    Parameters:\n",
        "    fragment_stack (list): The stack of NFA fragments.\n",
        "    id (int): The id of the new NFA, used to label the states.\n",
        "\n",
        "    Returns:\n",
        "    NFA: The NFA resulting from one or more of the top NFA on the stack.\n",
        "    '''\n",
        "    #pop the top NFA from the stack\n",
        "    nfa = fragment_stack.pop()\n",
        "    #create two new states for the new NFA\n",
        "    initial = NFA_state()\n",
        "    accept = NFA_state()\n",
        "    initial.label = f\"S{id}\"\n",
        "    accept.label = f\"S{id+1}\"\n",
        "    #create an edge from the new initial state to the start state of the NFA\n",
        "    edg1 = edge()\n",
        "    edg1.label = \"ε\"\n",
        "    edg1.destination = nfa.start\n",
        "    initial.out_edges.append(edg1)\n",
        "    #create two edges from the accept state of the NFA to the new accept state and to the initial state of the new NFA\n",
        "    edg2 = edge()\n",
        "    edg2.label = \"ε\"\n",
        "    edg2.destination = accept\n",
        "    nfa.accept.out_edges.append(edg2)\n",
        "    edg3 = edge()\n",
        "    edg3.label = \"ε\"\n",
        "    edg3.destination = initial\n",
        "    nfa.accept.out_edges.append(edg3)\n",
        "    #push the one or more NFA back to the stack\n",
        "    one_or_more_nfa = NFA(initial, accept, [initial, accept] + nfa.inner_states)\n",
        "    fragment_stack.append(one_or_more_nfa)\n",
        "    id += 2\n",
        "    return one_or_more_nfa\n",
        "\n",
        "def zero_or_one_nfa(fragment_stack, id: int):\n",
        "    '''\n",
        "    Zero or one of an NFA, popping it from the stack and pushing the result back.\n",
        "\n",
        "    Parameters:\n",
        "    fragment_stack (list): The stack of NFA fragments.\n",
        "    id (int): The id of the new NFA, used to label the states.\n",
        "\n",
        "    Returns:\n",
        "    NFA: The NFA resulting from zero or one of the top NFA on the stack.\n",
        "    '''\n",
        "    #pop the top NFA from the stack\n",
        "    nfa = fragment_stack.pop()\n",
        "    #create two new states for the new NFA\n",
        "    initial = NFA_state()\n",
        "    accept = NFA_state()\n",
        "    initial.label = f\"S{id}\"\n",
        "    accept.label = f\"S{id+1}\"\n",
        "    #create two edges from the new initial state to the start state of the NFA and to the new accept state\n",
        "    edg1 = edge()\n",
        "    edg1.label = \"ε\"\n",
        "    edg1.destination = nfa.start\n",
        "    initial.out_edges.append(edg1)\n",
        "    edg2 = edge()\n",
        "    edg2.label = \"ε\"\n",
        "    edg2.destination = accept\n",
        "    initial.out_edges.append(edg2)\n",
        "    #create an edge from the accept state of the NFA to the new accept state\n",
        "    edg3 = edge()\n",
        "    edg3.label = \"ε\"\n",
        "    edg3.destination = accept\n",
        "    nfa.accept.out_edges.append(edg3)\n",
        "    #push the zero or one NFA back to the stack\n",
        "    zero_or_one_nfa = NFA(initial, accept, [initial, accept] + nfa.inner_states)\n",
        "    fragment_stack.append(zero_or_one_nfa)\n",
        "    id += 2\n",
        "    return zero_or_one_nfa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RP6fylNhDkZh"
      },
      "outputs": [],
      "source": [
        "def thompson_construction_postfix_to_nfa(postfix):\n",
        "    '''\n",
        "    Convert a postfix regular expression to an NFA using the Thompson construction algorithm.\n",
        "\n",
        "    Parameters:\n",
        "    postfix (str): The postfix regular expression to convert to an NFA.\n",
        "\n",
        "    Returns:\n",
        "    NFA: The NFA resulting from the postfix regular expression.\n",
        "    '''\n",
        "    # Create an empty stack to hold the NFA fragments\n",
        "    fragment_stack = []\n",
        "    #dummy id for the states\n",
        "    id = 0\n",
        "    # Iterate over the characters in the postfix regular expression\n",
        "    for char in postfix:\n",
        "        if char in alphanumeric:\n",
        "            create_nfa(char, id, fragment_stack)\n",
        "        elif char == '.':\n",
        "            concatenate_nfas(fragment_stack)\n",
        "        elif char == '|':\n",
        "            union_nfas(fragment_stack, id)\n",
        "        elif char == '*':\n",
        "            zero_or_more_nfa(fragment_stack, id)\n",
        "        elif char == '+':\n",
        "            one_or_more_nfa(fragment_stack, id)\n",
        "        elif char == '?':\n",
        "            zero_or_one_nfa(fragment_stack, id)\n",
        "        else:\n",
        "            raise ValueError(f'Invalid character in postfix regular expression: {char}')\n",
        "        id += 2\n",
        "    #adjust IDs\n",
        "    normal_id = 0\n",
        "    for i, state in enumerate(fragment_stack[0].inner_states):\n",
        "        #if not accept state\n",
        "        if state != fragment_stack[0].accept:\n",
        "            state.label = f\"S{normal_id}\"\n",
        "            normal_id += 1\n",
        "    fragment_stack[0].accept.label = f\"S{normal_id}\"\n",
        "    # Return the resulting NFA\n",
        "    return fragment_stack.pop()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eycMAD3kLXjd"
      },
      "outputs": [],
      "source": [
        "# Output NFA to JSON of the following format:\n",
        "'''\n",
        "{\n",
        "\"startingState\": \"S0\",\n",
        "\"S0\": {\n",
        "\"isTerminatingState\": false,\n",
        "\"A\": \"S1\",\n",
        "\"B\": \"S0\"\n",
        "},\n",
        "\"S1\": {\n",
        "\"isTerminatingState\": true,\n",
        "\"A\": \"S1\",\n",
        "\"B\": \"S1\"\n",
        "}\n",
        "}\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "def nfa_to_json(nfa):\n",
        "    '''\n",
        "    Convert an NFA to a JSON representation.\n",
        "\n",
        "    Parameters:\n",
        "    nfa (NFA): The NFA to convert to JSON.\n",
        "\n",
        "    Returns:\n",
        "    str: The JSON representation of the NFA.\n",
        "    '''\n",
        "    json = '{\\n'\n",
        "    json += f'\"startingState\": \"{nfa.start.label}\",\\n'\n",
        "    for state in nfa.inner_states:\n",
        "        json += f'\"{state.label}\":'\n",
        "        json += '{\\n'\n",
        "        json += f'\"isTerminatingState\": {state == nfa.accept},\\n'\n",
        "        for edge in state.out_edges:\n",
        "            json += f'\"{edge.label}\": \"{edge.destination.label}\",\\n'\n",
        "        json = json[:-2] + '\\n'\n",
        "        json += '},\\n'\n",
        "    json = json[:-2] + '\\n'\n",
        "    json += '}\\n'\n",
        "    #save to file\n",
        "    with open('NFA.json', 'w') as f:\n",
        "        f.write(json)\n",
        "    return json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fcEsDXrvDkZh",
        "outputId": "24e4d283-fd04-4690-d833-0f83c6a67af7"
      },
      "outputs": [],
      "source": [
        "# Test cases\n",
        "# ----------\n",
        "# def test_postfix_to_nfa(id, postfix, expected_nfa):\n",
        "#     nfa = thompson_construction_postfix_to_nfa(postfix)\n",
        "#     print(f\"Test case #{id} : {postfix} received : {nfa} expected : {expected_nfa} => Passed\")\n",
        "#     assert nfa == expected_nfa\n",
        "\n",
        "# # Test case 1\n",
        "# regex = 'a|b*'\n",
        "# postfix = infix_to_postfix(regex)\n",
        "# nfa = thompson_construction_postfix_to_nfa(postfix)\n",
        "# nfa.print_graph()\n",
        "# print(nfa_to_json(nfa))\n",
        "# nfa.visualize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTkzI_CgMIHe"
      },
      "source": [
        "# Testing Cell : user input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "z-F0PbEjDkZh",
        "outputId": "d9984ab6-4212-4b5e-901d-d62bf817655f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After step 1 : a|b\n",
            "i = 0, c = a\n",
            "i = 1, c = |\n",
            "i = 2, c = b\n",
            "After step 2 : a|b\n",
            "After step 3 : a|b Preprocessed!\n",
            "NFA graph:\n",
            "State S0 :\n",
            "  edge ε going to S1\n",
            "  edge ε going to S3\n",
            "State S5 :\n",
            "State S1 :\n",
            "  edge a going to S2\n",
            "State S2 :\n",
            "  edge ε going to S5\n",
            "State S3 :\n",
            "  edge b going to S4\n",
            "State S4 :\n",
            "  edge ε going to S5\n",
            "Start state : S0\n",
            "Accept state : S5\n",
            "NFA saved to NFA.json\n"
          ]
        },
        {
          "data": {
            "image/svg+xml": [
              "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
              "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
              " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
              "<!-- Generated by graphviz version 2.43.0 (0)\n",
              " -->\n",
              "<!-- Title: %3 Pages: 1 -->\n",
              "<svg width=\"357pt\" height=\"98pt\"\n",
              " viewBox=\"0.00 0.00 357.50 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
              "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n",
              "<title>%3</title>\n",
              "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-94 353.5,-94 353.5,4 -4,4\"/>\n",
              "<!-- S0 -->\n",
              "<g id=\"node1\" class=\"node\">\n",
              "<title>S0</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-45\" rx=\"27\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"27\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">S0</text>\n",
              "</g>\n",
              "<!-- S1 -->\n",
              "<g id=\"node3\" class=\"node\">\n",
              "<title>S1</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"125\" cy=\"-72\" rx=\"27\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"125\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">S1</text>\n",
              "</g>\n",
              "<!-- S0&#45;&gt;S1 -->\n",
              "<g id=\"edge1\" class=\"edge\">\n",
              "<title>S0&#45;&gt;S1</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M52.22,-51.81C63.71,-55.04 77.62,-58.96 90.13,-62.47\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"89.21,-65.85 99.78,-65.19 91.1,-59.11 89.21,-65.85\"/>\n",
              "<text text-anchor=\"middle\" x=\"76\" y=\"-62.8\" font-family=\"Times,serif\" font-size=\"14.00\">ε</text>\n",
              "</g>\n",
              "<!-- S3 -->\n",
              "<g id=\"node5\" class=\"node\">\n",
              "<title>S3</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"125\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"125\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">S3</text>\n",
              "</g>\n",
              "<!-- S0&#45;&gt;S3 -->\n",
              "<g id=\"edge2\" class=\"edge\">\n",
              "<title>S0&#45;&gt;S3</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M52.22,-38.19C63.71,-34.96 77.62,-31.04 90.13,-27.53\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"91.1,-30.89 99.78,-24.81 89.21,-24.15 91.1,-30.89\"/>\n",
              "<text text-anchor=\"middle\" x=\"76\" y=\"-35.8\" font-family=\"Times,serif\" font-size=\"14.00\">ε</text>\n",
              "</g>\n",
              "<!-- S5 -->\n",
              "<g id=\"node2\" class=\"node\">\n",
              "<title>S5</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"322.75\" cy=\"-45\" rx=\"22.96\" ry=\"22.96\"/>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"322.75\" cy=\"-45\" rx=\"27\" ry=\"27\"/>\n",
              "<text text-anchor=\"middle\" x=\"322.75\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">S5</text>\n",
              "</g>\n",
              "<!-- S2 -->\n",
              "<g id=\"node4\" class=\"node\">\n",
              "<title>S2</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"225\" cy=\"-72\" rx=\"27\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"225\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">S2</text>\n",
              "</g>\n",
              "<!-- S1&#45;&gt;S2 -->\n",
              "<g id=\"edge3\" class=\"edge\">\n",
              "<title>S1&#45;&gt;S2</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M152,-72C162.97,-72 175.92,-72 187.79,-72\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"187.87,-75.5 197.87,-72 187.87,-68.5 187.87,-75.5\"/>\n",
              "<text text-anchor=\"middle\" x=\"175\" y=\"-75.8\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n",
              "</g>\n",
              "<!-- S2&#45;&gt;S5 -->\n",
              "<g id=\"edge4\" class=\"edge\">\n",
              "<title>S2&#45;&gt;S5</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M250.16,-65.19C261.33,-62.04 274.8,-58.24 287.03,-54.79\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"288.25,-58.08 296.93,-52 286.35,-51.34 288.25,-58.08\"/>\n",
              "<text text-anchor=\"middle\" x=\"274\" y=\"-62.8\" font-family=\"Times,serif\" font-size=\"14.00\">ε</text>\n",
              "</g>\n",
              "<!-- S4 -->\n",
              "<g id=\"node6\" class=\"node\">\n",
              "<title>S4</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"225\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"225\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">S4</text>\n",
              "</g>\n",
              "<!-- S3&#45;&gt;S4 -->\n",
              "<g id=\"edge5\" class=\"edge\">\n",
              "<title>S3&#45;&gt;S4</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M152,-18C162.97,-18 175.92,-18 187.79,-18\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"187.87,-21.5 197.87,-18 187.87,-14.5 187.87,-21.5\"/>\n",
              "<text text-anchor=\"middle\" x=\"175\" y=\"-21.8\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n",
              "</g>\n",
              "<!-- S4&#45;&gt;S5 -->\n",
              "<g id=\"edge6\" class=\"edge\">\n",
              "<title>S4&#45;&gt;S5</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M250.16,-24.81C261.33,-27.96 274.8,-31.76 287.03,-35.21\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"286.35,-38.66 296.93,-38 288.25,-31.92 286.35,-38.66\"/>\n",
              "<text text-anchor=\"middle\" x=\"274\" y=\"-35.8\" font-family=\"Times,serif\" font-size=\"14.00\">ε</text>\n",
              "</g>\n",
              "</g>\n",
              "</svg>\n"
            ],
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x79c1a34e7550>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def test_user_input():\n",
        "    regex = input(\"Enter a regular expression: \")\n",
        "    postfix = infix_to_postfix(regex)\n",
        "    nfa = thompson_construction_postfix_to_nfa(postfix)\n",
        "    nfa.print_graph()\n",
        "    nfa_to_json(nfa)\n",
        "    print(\"NFA saved to NFA.json\")\n",
        "    return nfa, postfix\n",
        "\n",
        "nfa, postfix = test_user_input()\n",
        "nfa.visualize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VFCGDHSZL6Pk"
      },
      "outputs": [],
      "source": [
        "def get_input_characters(postfix: str) -> list[str]:\n",
        "    input_chars = []\n",
        "    escaped_flag = False\n",
        "    for c in postfix:\n",
        "        if c in alphanumeric or escaped_flag:\n",
        "            input_chars.append(c)\n",
        "            escaped_flag = False\n",
        "        if c == '/':\n",
        "            escaped_flag = True\n",
        "    return input_chars\n",
        "\n",
        "\n",
        "def powerset_construction(nfa: NFA, alphabet: str) -> DFA:\n",
        "    dfa = DFA(nfa)\n",
        "    unmarked_states = set()\n",
        "    unmarked_states.add(dfa.start_super_state)\n",
        "    while unmarked_states:\n",
        "        current_super_state:SuperState = unmarked_states.pop()\n",
        "        for char in alphabet:\n",
        "            generated_super_state = current_super_state.generate_new_superstate(char)\n",
        "            \n",
        "            if generated_super_state and generated_super_state.sub_states:\n",
        "                existing_super_state = dfa.get_super_state(generated_super_state)\n",
        "                if not existing_super_state:\n",
        "                    new_super_state = SuperState()\n",
        "                    new_super_state.sub_states = generated_super_state.sub_states\n",
        "                    new_super_state.label = \"S\" + str(len(dfa.super_states))\n",
        "                    dfa.super_states.add(new_super_state)\n",
        "                    unmarked_states.add(new_super_state)\n",
        "                    current_super_state.out_edges.append(edge(char, new_super_state)) \n",
        "                else:\n",
        "                    current_super_state.out_edges.append(edge(char, existing_super_state))\n",
        "\n",
        "    for super_state in dfa.super_states:\n",
        "        for sub_state in super_state.sub_states:\n",
        "            if sub_state == nfa.accept:\n",
        "                super_state.is_end = True\n",
        "                dfa.accept_super_states.add(super_state)\n",
        "\n",
        "    return dfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_nfa_state(state_label:str) -> NFA_state:\n",
        "    nfa_state = NFA_state()\n",
        "    nfa_state.label = state_label\n",
        "    return nfa_state\n",
        "\n",
        "def min_DFA(dfa: DFA, input_chars: str) -> DFA:\n",
        "    #initialize the lower triangular matrix\n",
        "    lower_tri_matrix = LowerTriangularMatrix(len(dfa.super_states))\n",
        "    lower_tri_matrix.fill_with_dfa(dfa)\n",
        "    lower_tri_matrix.iterate_to_min_dfa(dfa, input_chars)\n",
        "    new_dfa = DFA()\n",
        "\n",
        "    # dictionary of [int, set]\n",
        "    new_states = dict()\n",
        "    id = 0\n",
        "    for pair in lower_tri_matrix.pairs.keys():\n",
        "        if lower_tri_matrix.get(pair[0], pair[1]) == \"∅\":\n",
        "            s0 = dfa.get_super_state_from_label(pair[0])\n",
        "            s1 = dfa.get_super_state_from_label(pair[1])\n",
        "\n",
        "            # if the new_states is empty => create a new set\n",
        "            if not new_states:\n",
        "                new_states[id] = {s0, s1}\n",
        "                id += 1\n",
        "            else:\n",
        "                # check if the pair[0] or pair[1] are in any of the sets\n",
        "                found = False\n",
        "                for key in new_states.keys():\n",
        "                    if s0 in new_states[key] or s1 in new_states[key]:\n",
        "                        new_states[key].add(s0)\n",
        "                        new_states[key].add(s1)\n",
        "                        found = True\n",
        "                        break\n",
        "                if not found:\n",
        "                    new_states[id] = {s0, s1}\n",
        "                    id += 1\n",
        "\n",
        "    # iterate over the matrix to add the states that does not appear in the dictionary values\n",
        "    for pair in lower_tri_matrix.pairs.keys():\n",
        "        if lower_tri_matrix.get(pair[0], pair[1]) != \"∅\":\n",
        "            s0 = dfa.get_super_state_from_label(pair[0])\n",
        "            s1 = dfa.get_super_state_from_label(pair[1])\n",
        "            found_1 = False\n",
        "            for key in new_states.keys():\n",
        "                if s0 in new_states[key]:\n",
        "                    found_1 = True\n",
        "                    break\n",
        "            if not found_1:\n",
        "                new_states[id] = {s0}\n",
        "                id += 1\n",
        "\n",
        "            found_2 = False\n",
        "            for key in new_states.keys():\n",
        "                if s1 in new_states[key]:\n",
        "                    found_2 = True\n",
        "                    break\n",
        "            if not found_2:\n",
        "                new_states[id] = {s1}\n",
        "                id += 1\n",
        "\n",
        "\n",
        "    # create a new dictionary the key is the representitive of the superstate and the value is a list of the superstates\n",
        "    super_states_with_representatives = dict()\n",
        "    for key in new_states.keys():\n",
        "        curr_states_list = list(new_states[key])\n",
        "        representativ_state = curr_states_list[0]\n",
        "        super_states_with_representatives[representativ_state.label] = curr_states_list\n",
        "\n",
        "    new_super_states = set()\n",
        "    # Create SuperStates for each representitive and connect the edges from each representitive to other representitives\n",
        "    for key in super_states_with_representatives.keys():\n",
        "        super_state = SuperState()\n",
        "        super_state.label = key\n",
        "        representative = super_states_with_representatives[key][0]\n",
        "        for repr_edge in representative.out_edges:\n",
        "            curr_dest = repr_edge.destination\n",
        "            dest_representative = None\n",
        "            for key in super_states_with_representatives.keys():\n",
        "                if curr_dest in super_states_with_representatives[key]:\n",
        "                    dest_representative = super_states_with_representatives[key][0]\n",
        "                    break\n",
        "            if dest_representative:\n",
        "                \n",
        "                super_state.out_edges.append(edge(repr_edge.label, dest_representative))\n",
        "\n",
        "        # print the current state and its output edges:\n",
        "        print(f\"State : {super_state.label}\")\n",
        "        for e in super_state.out_edges:\n",
        "            print(f\"Edge : {e.label} -> {e.destination.label}\")\n",
        "        new_super_states.add(super_state)\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # set the start state, loop over the super_states_with_representatives to find the start state\n",
        "    for key in super_states_with_representatives.keys():\n",
        "        found_start = False\n",
        "        if dfa.start_super_state in super_states_with_representatives[key]:\n",
        "            # get this representitive from the new_super_states\n",
        "            for state in new_super_states:\n",
        "                if state.label == key:\n",
        "                    new_dfa.start_super_state = state\n",
        "                    found_start = True\n",
        "                    break\n",
        "        if found_start:\n",
        "            break\n",
        "    \n",
        "    # set the accept states, loop over the super_states_with_representatives to find the accept states\n",
        "    for key in super_states_with_representatives.keys():\n",
        "        found_accept = False\n",
        "        for accept_state in dfa.accept_super_states:\n",
        "            if accept_state in super_states_with_representatives[key]:\n",
        "                # get this representitive from the new_super_states\n",
        "                for state in new_super_states:\n",
        "                    if state.label == key:\n",
        "                        new_dfa.accept_super_states.add(state)\n",
        "                        found_accept = True\n",
        "                        break\n",
        "            if found_accept:\n",
        "                break\n",
        "\n",
        "    new_dfa.super_states = new_super_states\n",
        "\n",
        "    return new_dfa\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Construct_minDFA_Json (dfa: DFA):\n",
        "      output_json = dict()\n",
        "      for stat in dfa.super_states:\n",
        "        if(stat.is_start):\n",
        "          output_json[\"starting_state\"] = stat.label\n",
        "        state_dict = dict()\n",
        "        if stat.is_end:\n",
        "          state_dict[\"is_terminating_state\"] = True\n",
        "        else:\n",
        "          state_dict[\"is_terminating_state\"] = False\n",
        "        for edg in stat.out_edges:\n",
        "          if(edg.label in state_dict.keys()):\n",
        "            state_dict[edg.label] = [] + [state_dict[edg.label]] + [edg.destination]\n",
        "            #state_dict[edg.label].append(edg.destination)\n",
        "          else:\n",
        "            state_dict[edg.label] = edg.destination\n",
        "        output_json[stat.label] = state_dict\n",
        "      minDFA_out_file = open('minDFA.json', 'w')\n",
        "      json_obj = json.dump(output_json, minDFA_out_file,indent=6, ensure_ascii=False)\n",
        "      minDFA_out_file.close()\n",
        "      return json_obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'digraph {\\n\\tgraph [label=\"DFA Cleaned\" rankdir=LR]\\n\\tS1 [peripheries=2]\\n\\tS2 [peripheries=2]\\n\\t\"\" [shape=none]\\n\\t\"\" -> S0\\n\\tS0\\n\\tS0 -> S1 [label=a]\\n\\tS0 -> S2 [label=b]\\n}\\n'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_chars = get_input_characters(postfix)\n",
        "dfa = powerset_construction(nfa, input_chars)\n",
        "dfa.visualize_normal()\n",
        "dfa.visualize('DFA Cleaned')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State : S1\n",
            "State : S0\n",
            "Edge : a -> S1\n",
            "Edge : b -> S1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'digraph {\\n\\tgraph [label=minDFA rankdir=LR]\\n\\tS0\\n\\tS1\\n\\tS0 -> S1 [label=a]\\n\\tS0 -> S1 [label=b]\\n}\\n'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "min_dfa = min_DFA(dfa, input_chars)\n",
        "\n",
        "\n",
        "min_dfa.visualize(\"minDFA\")\n",
        "#Construct_minDFA_Json(min_dfa)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
